scheduling section:
-----------------------
Manual scheduling:
-----------
how schedling works
--------
apiVersion: v1
kind: pod
metadata:
  name: nginx
  labels:
    name: nginx
spec:
  containers:
  - name: nginx
    image: nginx
    ports:
      - containerPort: 8080
  nodeName: node02

---------
apiversion: v1
kind: pod
metadata:
  name: nginx
spec: 
  nodeName: master
  containers:
  -  image: nginx
     name: nginx
--------------------------------
Labels and Selectors:
-----------------
Labels:

apiversion: v1
kind: pod
metadata:
  name: simple-webapp
  labels:
      app: App1
      function: Front-end

spec:
  containers:
  -  name: simple-webapp
     image: simple-webapp
     ports:
       - containerPort: 8080
--> kubectl get pods --selector app=App1
--> kubectl get pods --show-labels
--> kubectl get pods -l env=dev 
--> kubeclt get pods -l env=dev --no-headers | wc  -l
--> kubectl pods -l bu=finance --no-headers | wc -l
--> kubectl get pods env=prod --no-headers
--> kubectl get all -l env=prod --no-headers
--> kubectl get all -l env=prod --no-headers | wc -l
--> kubectl get pods -l env=prod, bu=fiance
--> kubectl get pods -l env=prod,bu=finance,tier=frontend
--> kubectl create -f replicaset-definition-1.yaml
---------------------
Taints And Toleration:
----------
--> kubectl taint nodes node-name key=value:taint-effect
--> kubectl taint nodes node1 app=blue:noschedlue

Tolerations: pods

apiVersion:
kind: pod
metadata:
 name: myapp-pod
spec:
  containers:
  - name: nginx-container
    image: nginx
  tolerations:
  - key: app
    operator:"Equal"
    value: blue
    effect: NoSchedule
--> kubectl desribe node kubemaster | grep taint
--> kubectl get nodes
--> kubectl describe node node01
--> kubectl describe node node01 | grep -i taint
--> kubectl taint node node01 spray=mortein:Noschedule
--> kubectl run mosquito --image=nginx --restart=Never
--> kubectl get pod mosquito
--> kubectl run bee --image=nginx --restart=never --dry-run -o yaml > bee.yaml
--> kubectl explain pod --recursive | less
--> kubectl explain pod --recursive | -A5 tolerations

apiVersion: v1
kind: pod
metadata:
  creationTimestamp: null
  labels:
    run: bee
  name: bee
spec:
  containers:
  - image: nginx
    name: bee
  tolerations:
  - effect: Noschedule
    key: spray
    operator: In
    value: mortein
--> kubectl apply -f bee.yaml
--> kubectl get pods
--> kubectl get pods -o wide
--> kubectl describe nodes master | grep -i taint
--> kubectl taint node master node-role.kubernetes.io/master:Noschedule
----------------
Node Selectors:
---
Node selectors
---
apiVersion:
kind: pod
metadata:
 name: myapp-pod
spec:
  containers:
  - name: data-processor
    image: data-processor
  
  nodeSelector:
    size: Large

----
Label Nodes:
--
--> kubectl label nodes <node-name> <label-key>=<label-value>
--> kubectl label nodes node-1 size=Large
-------
Node Selector:
apiVersion:
kind: pod
metadata:
 name: myapp-pod
spec:
  containers:
  - name: data-processor
    image: data-processor
 
  nodeSelector:
    size: Large
--> kubectl create -f pod-definition.yml
--------
Node Affinity
---------------
Node Affinity types:
Available:
requiredDuringSchedulingIgnoredDuringExecution
preferredDuringSchedulingIgnoredDuringExecution

Planned:
requiredDuringSchedulingRequiredDuringExecution
------
Solution: Node affinity
--> kubectl get nodes node01 --show-labels
--> kubectl label nodes node01 color=blue
--> kubectl create deployment blue --image=nginx
--> kubectl scale deployment blue --replicas=6
--> kubectl get pods -o wide
--> kubectl get deployments.app blue -o yaml > blue.yaml
--> kubectl delete deployments.apps blue
--> kubectl apply -f blue.yaml
--> kubectl get pods
--> kubectl create deployment red --image=nginx --dry-run -o yaml > red.yaml
--> kubectl get pods -o wide| grep red
------
node Affinity vs Taints and tolerations:
---------------------------------------
Resource requirements and limits:
---------------------
Resources Requests:

--> CPU-0.5
--> MEM: 256 Mi
--> Disk: 

apiVersion: v1
kind: pod
metadata:
  name: simple-webapp-color
  labels:
  name: simple-webapp-color
spec:  
  containers:
  - name: simple-webapp-color
    image: simple-webapp-color
    ports:
      - containerPort: 8080
    resources:
      requests
        memory: "IGi"
        cpu: 1

--> Resources: CPU
--> 1 AWS vCPU
--> 1 GCP Core
--> 1 Azure Core
--> 1 hyperthread

Resources: Memory

----------------------
Resources limits:
---------------
apiVersion: v1
kind: pod
metadata:
  name: simple-webapp-color
  labels: 
    name: simple-webapp-color
spec:
  containers:
  - name: simple-webapp-color
    image: simple-webapp-color
    ports:
      - containerPort: 8080
    resources:
      requests:
        memory: "1Gi"
        cpu: 1
      limits:
        memory: "2Gi"
        cpu: 2
----------------------------------
Note on default resource requirements and limits:

"When a pod is created the containers are assigned a default CPU request of .5 and memory of 256Mi". For the POD to pick up those defaults you must have first set those as default values for request and limit by creating a LimitRange in that namespace.

apiVersion: v1
kind: LimitRange
metadata:
  name: mem-limit-range
spec:
  limits:
  - default:
      memory: 512Mi
    defaultRequest:
      memory: 256Mi
    type: Container

apiVersion: v1
kind: LimitRange
metadata:
  name: cpu-limit-range
spec:
  limits:
  - default:
      cpu: 1
    defaultRequest:
      cpu: 0.5
    type: Container
------------------------------------
Solution: Resources limits:
-----------
Daemon Set:
-------------------
Daemons set is a like replicaSet
---
Daemon Sets -useCase -Kube-proxy
----
DaemonSet Definition
apiVersion: apps/v1
kind: Replicaset
metadata:
  name: monitoring-daemon
spec:
  selector:
    matchLabels:
      app: monitoring-agent
  template:
    metadata:
      labels:
        app: monitroing-agent
    spec:
      containers;
      - name: monitoring-agent
        image: monitoring-agent

view Daemonsets:
--> kubectl get daemonsets
--> kubectl describe daemonsets monitoring-daemon
--> kubectl get ds --all-namespaces
--> kubectl get nodes
--> kubectl -n kube-system get pods | grep proxy
--> kubectl -n kube-system get pods -o wide | grep proxy
--> kubectl -n kube-system decribe ds weave-net | grep -i image
--> kubectl create deployment --image=k8.gcr.io/fluentd-elasticsearch:1.20 --dry-run -o yaml > elastic.yaml
----------------------------
Static Pods:
-------
--> kubelet.service
--> kubconfig.yaml

Static pods vs Daemonsets:

Static pods:
--> created by the kubelet
--> Deploy control plane componenet as statis pods

Daemonsets:
--> Created by kube-API server (DaemonSet Controller)
--> Deploy Monitoring Agents, logging Agents on nodes

Solution: Static pods
--> kubectl get pods --all-namespaces
--> kubectl get pods --all-namespaces | grep "\-master"
--> kubectl get pods --all-namespaces -o wide | grep "\-master"
--> ps -ef | grep kubelet
--> grep -i static /var/lib/kubelet/config.yaml
--> grep -i image kube-apiserver.yaml
--> kubectl run statis-busybox --image=busybox --command sleep 1000 --restart=never --dry-run -o yaml > static-busybox.yaml
--> ps -ef | grep kubelet | grep "\--config"
--> grep -i static /var/lib/kubelet/config.yaml

-----------------------------------
Multiple Scheduler:
---------------------
deploy Additional Scheduler -kubeadm
/etc/kubernetes/manifests/kube-scheduler.yaml

apiVersion: v1
kind: pod
metadata:
  name: kube-scheduler
  namespace: kube-system
spec:
  containers:
  - command:
    - kube-scheduler
    - --address=127.0.0.1
    - --kubeconfig=/etc/kubernetes/scheduler.conf
    - --leader-elect=true
    - --scheduler-name=my-custom-scheduler
    - --lock-bkect-name=my-custom-scheduler
image: k8s.gcr.io/kube-scheduler=amd64:v1.11.3
    name: kube-scheduler
-----------
apiversion: v1
kind: pod
metadata:
  name: nginx
spec:
  containers:
  - image: nginx
    name: nginx

  schedulerName: my-custom-scheduler

--> kubectl get events

View scheduler logs:

--> kubectl logs my-custom-scheduler --name-space=kube-system
--> kubectl -n kube-system desribe pod kube-scheduler-master | grep image







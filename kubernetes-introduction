Cluster Architecture:
--> kubernetes architecture
--> ETCD 
--> Kube-API server
--> Controller managers
--> kube scheduler
--> kubelet
--> kube proxy


Master and worker nodes
---------------------
1. ETCD:
is a distributed reliable key value store that is simple, secure and fast.

--> Key-value store:
its tabular/Relational Databases

--> Install ETCD:
1. download Binaries:
curl -L https://github.com/etcd-io/etcd/releases/download/v3.3.11/etcd-v3.3.11-linux-amd64.tar.gz -o etcd-v3.3.11-linux-amd64.tar.gz

2. extract 
tar xzvf etcd-v3.3.11-linux-amd64.tar.gz

3. run ETCD service
./etcd

Default port for etcd listen: 2379

to set key-value
./etcdctl set key1 value1
./etcdctl get key1
./etcdctl

---------------------
when you setup--kubeadm
kubectl get pod -n kube-system

to list all the key-run inside the etcd-master POD
--> kubectl exec etcd-master -n kube-system etcdctl get / --prefix -keys-only

ETCD -commands (optional)
ETCDCTL is the CLI tool used to interact with ETCD

ETCDCTL can interact with ETCD server using 2 API versions
-version 2 and version 3.

ETCDCTL version 2 supports:
--> etcdctl backup
--> etcdctl cluster-health
--> etcdctl mk
--> etcdctl mkdir
--> etcdctl set

the commands are different in versions 3:
--> etcdctl snapshot save
--> etcdctl endpoint health
--> etcdctl get
--> etcdctl put

To set the right version of API set the environment variable ETCDCTl_API=3

When API version is not set, it is assumed to be set to version 2 and 3

ETCDCTL can authenticate to the ETCD API server.
The Certificate files are available in the etcd-master at the following path.

--> cacert /etc/kubernetes/pki/etcd/ca.crt
--> cert /etc/kubernetes/pki/etcd/server.crt
--> key /etc/kubernetes/pki/etcd/server.key

the ETCDCTL API versio and path to certificate files.
--> kubectl exec etcd-master -n kube-system -- sh -c "ETCDCTL_API=3 etcdctl get / --prefix --keys-only --limit=10 --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/server.crt  --key /etc/kubernetes/pki/etcd/server.key" 
-------------------------
2. kube-API server:
--> curl -X POST /api/v1/namespaces/default/pods ..
pods created

1. Authenticate user
2. Validate Request
3. Retrieve data
4. Update ETCD
5. Scheduler
6. kubelet

installing kube-api server
--> wget https://storage.gooleapis.com/kubernetes-release/release/v1.13.0/bin/liux/amd64/kube-apiserver
--(kube-apiserver.service)

--> View api-server options - kubeadm
cat /etc/kubernetes/manifests/kube-apiserver.yaml

cat /etc/systemd/system/kube-apiserver.service

running process
ps -aux  | grep kube-apiserver

--------------------------------------------
3. Kube Controller Manager:

--> Node-controller
 -> watch status
 -> remediate situation
 -> node monitor perios = 5s
 -> node montitor grace period = 40s
 -> pod eviction timeout = 5m

--> Replication-Controller

----
Installing kube-controller-manager
--> wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-controller-manager

kube-contrller-manger.service

-> View kube-controller-manager -kubeadm
cat /etc/kubernetes/manifests/kube-controller-manger.yaml

cat /etc/systemd/system/kube-controller-manger.service

ps -aux | grep kube-controller-manager

--> view kube-scheduler options-kubeadm 
cat /etc/kubernetes/manifests/kube-sceduler.yaml

--> to view kube-scheduler 
ps -aux | grep kube-scheduler

--------------------------------------------
4. kubelet
--> register node
--> create PODS
--> Monitor NOde & PODS

--> Installing Kubelet
wget https://storage.googleapis.com/kubernetes-release/v1.13.0/bin/linux/amd64/kubelet

kubelet.service

--> 
ps -aux | grep kubelet

------------------------
kube-proxy
---
to connect pod to pod then kubernets we are going to use

--> Installing kube-proxy
wget https://storage-googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-proxy

kube-proxy.service

--> to view kube-proxy kubeadm
kubectl get pods -n kube-system

kubectl get daemonset -n kube-system
------
Pod
----
kubectl
--> kubectl run nginx --image nginx

--------------------------
pod with yaml

apiVersion: v1
kind: pod
metadata:
  name: nginx
  labels: nginx
    app: nginx
    tier: frontend
spec:
  containers:
    - name: nginx
      image: nginx

--> kubectl create -f pod-defintion.yml
--> detail particular pod
 -> kubectl describe pod myapp-pod

----------------------------
kubectl run nginx --iamge=nginx
kubectl expose pod nginx --port 80 --type nodeport

kubectl run redis --image=redis123 --dry-run=client -o yaml > pod.yaml

apiVersion; v1
kind: pod
metadata:
  creationTimestamp: null 
  labels:
    run: redis
  name: redis
spec:
  containers:
  - image: redis
    name: redis
    resources: {}
  dnsPolicy; ClusterFirst
  restartPolicy: Always
status: {}
kubectl apply -f pod.yaml

kubectl edit pod redis
------------------------------
ReplicaSets:
---------
--> Replication-controller: helps to multiple instances of single pod
--> high availability

Load Balancing & Scaling:

apiVersion: v1
kind: ReplicationController
metadta:
  name: myapp-rc
  labels:
      app: myapp
      type: front-end
spec:
  template:

  metadata:
   name: myapp-pod
   labels:
      app: myapp
      type: front-end
  spec:
    container:
    - name: nginx-container
      image: nginx
 replicas: 3

--> kubectl create -f rc-defintion.yml 
--> kubectl get replicaset
--> kubectl scale --replicas=6 replicaset-definition.yml
--> kubectl scale --replicas=6 replicaset myapp-replicaset 
--> kubectl delete replicaset myapp-repicaset-->deletes all underlying PODs
--> kubectl repace -f replicaset-definition

---------
Deployments:
------------------------
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-deployment
  labels:
      app: myapp
      type: front-end
spec:
  template:
    metadata:
     name: myapp-pod
     labels:
        app: myapp
        type: front-end
     spec:
       containers:
       - name: nginx-container
         image: nginx
     replicas: 3
     selector:
        matchLabels:
           type: front-end
--> kubectl create -f deployment-definition
--> kubectl get deployments
--> kubectl get replicaset
--> kubectl get all

reate an NGINX Pod

kubectl run nginx --image=nginx

Generate POD Manifest YAML file (-o yaml). Don't create it(--dry-run)

kubectl run nginx --image=nginx --dry-run=client -o yaml

Create a deployment

kubectl create deployment --image=nginx nginx

Generate Deployment YAML file (-o yaml). Don't create it(--dry-run)

kubectl create deployment --image=nginx nginx --dry-run=client -o yaml

Generate Deployment YAML file (-o yaml). Don't create it(--dry-run) with 4 Replicas (--replicas=4)

kubectl create deployment --image=nginx nginx --dry-run=client -o yaml > nginx-deployment.yaml

Save it to a file, make necessary changes to the file (for example, adding more replicas) and then create the deployment.

kubectl create -f nginx-deployment.yaml

OR

In k8s version 1.19+, we can specify the --replicas option to create a deployment with 4 replicas.

kubectl create deployment --image=nginx nginx --replicas=4 --dry-run=client -o yaml > nginx-deployment.yaml

-------------------------------
Namespaces:
----------------
to list with names
--> kubectl get pods --namespace=kube-system

apiVersion: v1
kind: pod

metadat:
 name: myapp-pod
 namespace: dev
 labels:
    app: myapp
    type: front-end
spec:
  containers:
  - name: nginx-container
    image: nginx
--> kubectl create -f pod-defintion.yml
--> kubectl create -f pod-definition.yml --namespace=dev

-----
how you do create new namespace:
apiVersion: v1
kind: Namespace
metadata:
    name: dev
kubectl create -f namespace-dev.yml























